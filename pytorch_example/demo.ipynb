{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bm', 'Eg', 'Ba']\n",
      "begin to train mfcc by lstm\n",
      "/home/sheng/Desktop/audio-classification/pytorch_example/train_lstm.py:88: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  global_epoch_loss += loss.data[0]\n",
      "/home/sheng/Desktop/audio-classification/pytorch_example/train_lstm.py:96: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.4f' % accuracy)\n",
      "('Epoch: ', 0, '| train loss: 1.0750', '| test accuracy: 0.8961')\n",
      "('Epoch: ', 0, '| train loss: 0.0082', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0037', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.1881', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0003', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0073', '| test accuracy: 0.8961')\n",
      "('Epoch: ', 0, '| train loss: 0.0084', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0012', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0033', '| test accuracy: 0.9481')\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       116\n",
      "          1       1.00      0.24      0.38        17\n",
      "\n",
      "avg / total       0.91      0.90      0.87       133\n",
      "\n",
      "Confusion Matrix:\n",
      "[[116   0]\n",
      " [ 13   4]]\n",
      "Accuracy: 90.23%\n",
      "precision: 94.96%\n",
      "recall: 61.76%\n",
      "f1 score: 66.39%\n",
      "auc area: 61.76%\n",
      "('training time ', '1.2390 s')\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--train_wav_path TRAIN_WAV_PATH]\r\n",
      "               [--train_csv_path TRAIN_CSV_PATH] [--read_path READ_PATH]\r\n",
      "               [--cut CUT] [--padding PADDING] [--padding_path PADDING_PATH]\r\n",
      "               [--T_total N] [--redimension_train_path REDIMENSION_TRAIN_PATH]\r\n",
      "               [--redimension_prediction_path REDIMENSION_PREDICTION_PATH]\r\n",
      "               [--extract EXTRACT] [--image_train_path IMAGE_TRAIN_PATH]\r\n",
      "               [--image_prediction_path IMAGE_PREDICTION_PATH]\r\n",
      "               [--mfcc_length N] [--sample_size N] [--sample_rate N]\r\n",
      "               [--length N] [--width N] [--features_type FEATURES_TYPE]\r\n",
      "               [--batch_size N] [--arc ARC] [--epochs N] [--lr LR]\r\n",
      "               [--momentum M] [--optimizer OPTIMIZER] [--drop_out N]\r\n",
      "               [--split_ratio N] [--num_layers N] [--hidden_size N]\r\n",
      "               [--num_classes N]\r\n",
      "\r\n",
      "audio classification\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --train_wav_path TRAIN_WAV_PATH\r\n",
      "                        path to the train wav data folder\r\n",
      "  --train_csv_path TRAIN_CSV_PATH\r\n",
      "                        path to the train csv data folder\r\n",
      "  --read_path READ_PATH\r\n",
      "                        stock cut wav files\r\n",
      "  --cut CUT             if you excute the code at first time. please cut the\r\n",
      "                        raw wav by input True\r\n",
      "  --padding PADDING     if you excute the code at first time. please padding\r\n",
      "                        the raw wav by input True\r\n",
      "  --padding_path PADDING_PATH\r\n",
      "                        path to stock padding audio\r\n",
      "  --T_total N           define the max length of redimension wav\r\n",
      "  --redimension_train_path REDIMENSION_TRAIN_PATH\r\n",
      "                        path to redimension train wav folder\r\n",
      "  --redimension_prediction_path REDIMENSION_PREDICTION_PATH\r\n",
      "                        path to redimension train wav folder\r\n",
      "  --extract EXTRACT     if you excute the code at first time. please extract\r\n",
      "                        features by input True\r\n",
      "  --image_train_path IMAGE_TRAIN_PATH\r\n",
      "                        path to stock train image folder\r\n",
      "  --image_prediction_path IMAGE_PREDICTION_PATH\r\n",
      "                        path to stock train image folder\r\n",
      "  --mfcc_length N       define the max length of mfcc for lstm\r\n",
      "  --sample_size N       define the sample size of raw signal for lstm\r\n",
      "  --sample_rate N       define the sample rate of raw signal for lstm\r\n",
      "  --length N            define the max length (mfcc or image of raw signal)\r\n",
      "                        for cnn\r\n",
      "  --width N             define the max width (mfcc or image of raw signal) for\r\n",
      "                        cnn\r\n",
      "  --features_type FEATURES_TYPE\r\n",
      "                        type of features: mfcc,wavelet(only for network\r\n",
      "                        lstm),raw_signal\r\n",
      "  --batch_size N        training and valid batch size\r\n",
      "  --arc ARC             network architecture: lstm,cnn,wavenet\r\n",
      "  --epochs N            number of epochs to train\r\n",
      "  --lr LR               learning rate\r\n",
      "  --momentum M          SGD momentum, for SGD only\r\n",
      "  --optimizer OPTIMIZER\r\n",
      "                        optimization method: sgd | adam\r\n",
      "  --drop_out N          dropout\r\n",
      "  --split_ratio N       split test/train ratio\r\n",
      "  --num_layers N        number of layers\r\n",
      "  --hidden_size N       number of hidden size\r\n",
      "  --num_classes N       number of classes\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py  -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bm', 'Eg', 'Ba']\n",
      "begin to train mfcc by lstm\n",
      "/home/sheng/Desktop/audio-classification/pytorch_example/train_lstm.py:88: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  global_epoch_loss += loss.data[0]\n",
      "/home/sheng/Desktop/audio-classification/pytorch_example/train_lstm.py:96: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.4f' % accuracy)\n",
      "('Epoch: ', 0, '| train loss: 1.1680', '| test accuracy: 0.6104')\n",
      "('Epoch: ', 0, '| train loss: 0.0010', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0000', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0000', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0013', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.3257', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0014', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0030', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 0, '| train loss: 0.0002', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 1, '| train loss: 0.3503', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 1, '| train loss: 0.0000', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 1, '| train loss: 0.0000', '| test accuracy: 0.8701')\n",
      "('Epoch: ', 1, '| train loss: 0.0000', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 1, '| train loss: 0.4982', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 1, '| train loss: 0.0000', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 1, '| train loss: 0.0000', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 1, '| train loss: 0.5958', '| test accuracy: 0.9610')\n",
      "('Epoch: ', 1, '| train loss: 0.0000', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 2, '| train loss: 0.0000', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 2, '| train loss: 0.0000', '| test accuracy: 0.9610')\n",
      "('Epoch: ', 2, '| train loss: 0.0024', '| test accuracy: 0.6753')\n",
      "('Epoch: ', 2, '| train loss: 0.4754', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 2, '| train loss: 0.0006', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 2, '| train loss: 0.0004', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 2, '| train loss: 0.0131', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 2, '| train loss: 0.0000', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 2, '| train loss: 0.0001', '| test accuracy: 0.8961')\n",
      "('Epoch: ', 3, '| train loss: 0.5281', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 3, '| train loss: 0.0001', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 3, '| train loss: 0.0001', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 3, '| train loss: 0.0001', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 3, '| train loss: 0.0001', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 3, '| train loss: 0.4096', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 3, '| train loss: 0.0067', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 3, '| train loss: 0.0047', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 3, '| train loss: 0.0000', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 4, '| train loss: 0.0113', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 4, '| train loss: 0.0000', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 4, '| train loss: 0.0000', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 4, '| train loss: 0.0000', '| test accuracy: 0.9351')\n",
      "('Epoch: ', 4, '| train loss: 0.0000', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 4, '| train loss: 0.0000', '| test accuracy: 0.9221')\n",
      "('Epoch: ', 4, '| train loss: 0.0942', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 4, '| train loss: 0.0005', '| test accuracy: 0.9481')\n",
      "('Epoch: ', 4, '| train loss: 0.0383', '| test accuracy: 0.9481')\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00       116\n",
      "          1       0.94      1.00      0.97        17\n",
      "\n",
      "avg / total       0.99      0.99      0.99       133\n",
      "\n",
      "Confusion Matrix:\n",
      "[[115   1]\n",
      " [  0  17]]\n",
      "Accuracy: 99.25%\n",
      "precision: 97.22%\n",
      "recall: 99.57%\n",
      "f1 score: 98.35%\n",
      "auc area: 99.57%\n",
      "('training time ', '5.7535 s')\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
